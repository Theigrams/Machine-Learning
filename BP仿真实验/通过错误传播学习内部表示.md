[所有的东西](http://allthingsphi.com/index.html)

# 通过错误传播学习内部表示

## 动机（s）

每当输入和输出模式的相似性结构非常不同时，没有内部（隐藏）表示的神经网络将不能执行必要的映射。例如Minsky 和 Papert 提出的异或问题。

XOR问题的一个解决方案是在前两位有一个时，增加一个额外的第三个输入。另一个解决方案是添加一个隐藏的单元，将其馈入输出单元，这使隐藏单元在功能上等同于另一个输入单元。

德尔塔规则（感知器收敛过程）保证解决不需要隐藏单元的问题。隐藏单位网络缺乏这样的保证导致了网络的发展

- 无监督的学习规则，不保证适当的隐藏单位的学习，
- 具有域特定拓扑的隐藏单元和
- 一个学习算法采用随机单位玻尔兹曼机。

## 建议的解决方案

作者提出了广义增量规则作为具有确定性单元的 多层前向神经网络的替代学习过程。给定足够的范例，网络将找到问题的一般化解决方案，而无需指定实际的程序。

请注意，网络中的任何数量的权重都是可以修复的。错误仍像以前一样传播，但固定权重不被修改。此外，一些输出单元可能不会接收来自其他输出单元的输入。那些其他的输出单元将会收到两种不同的错误：

- 从与一些所希望的目标的直接比较误差，并且
- 错误从其影响激活的单位反向传播。

作者断言，在这种情况下正确的三角洲规则是加在一起的重量变化。

## 评估（s）

实验表明，网络学习了一个优雅的解决方案，以解决以下一系列问题：XOR，奇偶校验位，分布式表示编码，回文检测，二进制否定和二进制加法。然而，二进制加法的解决方案没有概括一半的时间。这个问题是别人的意义不同的是，隐藏的单位不是等电位，并增加额外的隐藏单元避免了错误配置。

另一个模拟是识别T或C字符而不依赖于平移和旋转。该网络由隐藏单元网格组成，其中每个隐藏单元在输入单元（例如3x3像素）上具有与其他接受域重叠的接受域。每个接收区域具有相同的形状，所有隐藏的单元都会馈送到一个输出单元中。显示五到一万个例子后，系统能够识别整个八种模式。

请注意，相同的学习规则适用于Sigma-Pi单位。这也适用于反复网络是因为每一个经常性的网络，存在前馈网络拥有超过的有限期限相同的行为时。然而，由于前馈网络必须将这些单元分层，使得单元不会影响相同层或更低层中的单元，所以在前向迭代期间，经常性网络的未来状态不会影响过去的状态。这个策略成功地解决了学习移位寄存器和字符序列完成。

有两个使用广义增量规则的训练网络的警告。对称破坏需要发生，可能通过随机初始化，否则直接连接到输出单元的所有隐藏单元将得到相同的错误信号。另一个问题是确定学习率。提高学习速率而不导致振荡的一种方法是包括动量项，该项用于滤除权重空间中的误差表面的高频变化。

## 未来方向

- 深度学习只专注于监督最终输出层。如何使用分层标签缩短深度训练时间？这些标签将是中间隐藏层的靶和可更新异步即对于$\alpha \in [0, 1]$

  $$\Delta_p w_{ji} \approx o^p_i f'_j\left( \text{net}^p_j \right) \left[ \alpha \left( o^p_j - t^p_j \right) + (1 - \alpha) \sum_k \delta^p_k w_{kj} \right].$$

- 如何使用固定权重作为实现神经网络收缩和增长的机制，即[适应任意](http://allthingsphi.com/blog/2016/11/30/information-processing-in-dynamical-systems-foundations-of-harmony-theory.html)[网络](http://allthingsphi.com/blog/2016/11/30/information-processing-in-dynamical-systems-foundations-of-harmony-theory.html)[的拓扑结构](http://allthingsphi.com/blog/2016/11/30/information-processing-in-dynamical-systems-foundations-of-harmony-theory.html)？

- 如何接近反向传播，通过时间用 [对比的分歧](http://allthingsphi.com/blog/2016/11/23/training-products-of-experts-by-minimizing-contrastive-divergence.html)？

## 问题

- 隐藏单元的数量如何改变网络的误差面？

## 分析

错误传播方案几乎可以在每个实验中得到解决方案，但不能保证找到解决方案。

编码实验表明，线性单元可以覆盖更宽的动态范围，并且在与不同的激活函数结合使用时改善整个网络。这似乎表明连续非线性 [激活函数本身应该学习](http://allthingsphi.com/blog/2016/11/15/maxout-networks.html)。

作者声称，逻辑函数是一个很好的激活函数，因为中点在$0.5$  ，而$\{0,1 \}$的 极值不能达到。然而，[最近的深度学习结果](http://allthingsphi.com/blog/2016/11/09/efficient-backprop.html) 表明，这个函数的消失梯度是非常有问题的。

值得进一步分析的一个有趣的地方是，通过增加隐藏单元的数量来减少找到解决方案的时间。

对于经常性网络，通过时间方案提出的反向传播让人怀疑大脑是否正在执行较少的内存密集型操作。

## 笔记

广义三角规则（又名反向传播）是 神经网络的监督学习过程。在输入/输出模式对上提出的误差测量是

$$E = \sum_p E_p = \sum_p \frac {1} {2} \sum_j（t ^ p_j - o ^ p_j）^ 2 $$

其中$t ^ p_j $是给定模式$p $的$j \text{th} $输出单元的目标值（标签），而 $o ^ p_j $是实际输出产生的输出模式$p $。

对于每个神经元$j $，其输出被定义为

$$o^p_j = f_j\left( \text{net}^p_j \right) = f_j\left( \sum_{i \in \text{parent}(o_j)} w_{ji} o^p_i \right)$$

其中$$o_i = i_i$$如果单元$i$ 是一输入单元，以及单元$j $的激活函数$f_j $是非线性的和微分的。

在误差相对于一重量的变化 $w_{ji}$是

$$\begin{split}\frac{\partial E}{\partial w_{ji}} &= \sum_p \frac{\partial E_p}{\partial w_{ji}}\\ &= \sum_p \frac{\partial E_p}{\partial o^p_j} \frac{\partial o^p_j}{\partial w_{ji}} & \quad & \text{chain rule}\\ &= \sum_p \frac{\partial E_p}{\partial o^p_j} \frac{\partial o^p_j}{\partial \text{net}^p_j} \frac{\partial \text{net}^p_j}{\partial w_{ji}} & \quad & \text{chain rule}\\ &= \sum_p \delta^p_j \frac{\partial \text{net}^p_j}{\partial w_{ji}} & \quad & \delta^p_j = \frac{\partial E_p}{\partial \text{net}^p_j} = \frac{\partial E_p}{\partial o^p_j} \frac{\partial o^p_j}{\partial \text{net}^p_j}\end{split}$$

where

$$\frac{\partial \text{net}^p_j}{\partial w_{ji}} = \frac{\partial}{\partial w_{ji}} \sum_{i \in \text{parent}(o_j)} w_{ji} o^p_i = o^p_i,$$

$$\frac{\partial o^p_j}{\partial \text{net}^p_j} = \frac{\partial}{\partial \text{net}^p_j} f_j\left( \text{net}^p_j \right) = f'_j\left( \text{net}^p_j \right),​$$

and

$$\frac{\partial E_p}{\partial o^p_j} = \frac{\partial}{\partial o^p_j} \frac{1}{2} \sum_j (t^p_j - o^p_j)^2 = o^p_j - t^p_j.$$

当神经元$j $不是输出单元时，

$$\begin{split}\frac{\partial E_p}{\partial o^p_j} &= \sum_{k \in \text{child}(o_j)} \frac{\partial E_p}{\partial \text{net}^p_k} \frac{\partial \text{net}^p_k}{\partial o^p_j}\\ &= \sum_k \delta^p_k \left( \frac{\partial}{\partial o^p_j} \sum_{i \in \text{parent}(o_k)} w_{ki} o^p_i \right)\\ &= \sum_k \delta^p_k w_{kj}.\end{split}$$

Therefore,

$$\begin{split}\Delta_p w_{ji} \approx \delta^p_j o^p_i \quad \text{with} \quad \delta^p_j = \begin{cases} f'_j\left( \text{net}^p_j \right) \left( o^p_j - t^p_j \right) & \text{if j is an output neuron,}\\ f'_j\left( \text{net}^p_j \right) \sum_{k \in \text{child}(o_j)} \delta^p_k w_{kj} & \text{otherwise.} \end{cases}\end{split}$$

参考

References

> David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning internal representations by error propagation. Technical Report, DTIC Document, 1985. 